{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function Definition__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov  9 12:00:31 2018\n",
    "\n",
    "@author: Hansheng Jiang\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "import scipy.linalg\n",
    "from itertools import combinations\n",
    "from numpy import linalg\n",
    "from numpy.linalg import matrix_rank\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import random\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import integrate\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.lines as mlines\n",
    "import scipy.stats\n",
    "import csv\n",
    "import statistics as stats\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "from scipy.integrate import quad\n",
    "\n",
    "from sympy import sin, cos, symbols, integrate\n",
    "\n",
    "np.random.seed(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmo(beta,X,y,sigma,f):\n",
    "    #return the objective funciton of the linear oprimization problem\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    obj = 0\n",
    "    for i in range(n):\n",
    "        obj = obj - np.exp(-0.5*(y[i] - np.dot(X[i],beta))**2 /(sigma**2))/f[i]\n",
    "    return obj  \n",
    "\n",
    "def jacobian(beta,X,y,sigma,f):\n",
    "    #return gradient of the linear objective function\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    jac = np.zeros((p,1))\n",
    "    for i in range(n):\n",
    "        temp = (y[i] - np.dot(X[i],beta))**2 /(sigma**2)\n",
    "        jac = jac - np.exp(-0.5*temp)*temp/f[i]/(sigma**2) * np.reshape(X[i],(p,1))\n",
    "        jac = np.reshape(jac,(p,1))\n",
    "    jac = np.reshape(jac, (p,))\n",
    "    return jac\n",
    "\n",
    "def hessian(beta,X,y,sigma,f):\n",
    "    #return Hessian of the linear objetive function\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    hess = np.zeros((p,p))\n",
    "    for i in range(n):\n",
    "        temp = (y[i] - np.dot(X[i],beta))**2 /(sigma**2)\n",
    "        x1 = np.reshape(X[i],(p,1))\n",
    "        x2 = np.reshape(X[i],(1,p))\n",
    "        temp2 = np.matmul(x1,x2)\n",
    "        hess = hess - (np.exp(-0.5*temp)*temp**2/(sigma** 4) -np.exp(-0.5*temp)/(sigma**2))/f[i]*temp2\n",
    "    return hess\n",
    "\n",
    "def sollmo(X,y,sigma,f):\n",
    "    #solve linear minimization oracle\n",
    "    #this is an nonconvex problem with respect to beta, the result is approximal\n",
    "    #return a new supporting vector g and corresponding beta\n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    \n",
    "    #sensitive to initialization!!!!\n",
    "    #initialize beta0 with OLS solution or beta = 0\n",
    "    beta0 = np.reshape(np.dot( np.matmul(linalg.inv(np.matmul(X.T,X)),X.T),y),(p,1)) \n",
    "    \n",
    "    \n",
    "    #minimize exponential sum approximately\n",
    "    #nonconvex problem\n",
    "    OptResult = minimize(lmo, beta0, args = (X,y,sigma,f),method = 'Powell')\n",
    "    beta_sol = OptResult.x\n",
    "    g = np.zeros((n,1))\n",
    "    for i in range(n):\n",
    "        g[i] = 1/(np.sqrt(2*np.pi)*sigma)* np.exp(-0.5*(y[i] - np.dot(X[i],beta_sol))**2 /(sigma**2))\n",
    "    return g,beta_sol\n",
    "\n",
    "def FW_FC(f,alpha,P,n):\n",
    "    #solve the fully corective step using classic FW\n",
    "    #warm start with f from last iteration\n",
    "    #P each column of P is a candidate component\n",
    "    #return new f, and f as a convex combination of columns of P with coefficients alpha\n",
    "    iter = 5000\n",
    "    \n",
    "    k = len(P[0])\n",
    "    alpha = np.append(alpha,0)\n",
    "    alpha = np.reshape(alpha,(k,1))\n",
    "    for t in range(1,iter):\n",
    "        g = 1/f\n",
    "        g = np.reshape(g,(1,n))\n",
    "        s = np.argmax(np.matmul(g,P))\n",
    "        gamma = 2/(t+2)\n",
    "        f = (1-gamma)*f +gamma*np.reshape(P[:,s],(n,1))\n",
    "        temp = np.zeros((k,1))\n",
    "        temp[s] = 1\n",
    "        alpha = (1-gamma)*np.reshape(alpha,(k,1))+gamma*temp\n",
    "    return f,alpha\n",
    "\n",
    "def NPMLE_FW(X,y,iter,sigma):\n",
    "    '''\n",
    "    Use FW algorithm to solve NPMLE problem of MLR  \n",
    "    sigma is estimated before\n",
    "    \n",
    "    '''  \n",
    "    n = len(X)\n",
    "    p = len(X[0])\n",
    "    \n",
    "    L_rec = []\n",
    "    \n",
    "    #initialize beta0 and f\n",
    "    beta0 = np.reshape(np.dot(np.matmul(linalg.inv(np.matmul(X.T,X)),X.T),y),(p,1)) #beta0 is OLS solution\n",
    "    #beta0 = np.zeros((p,1))\n",
    "    f = np.zeros((n,1))\n",
    "    for i in range(n):\n",
    "        f[i] = 1/(np.sqrt(2*np.pi)*sigma)* np.exp(-0.5*(y[i] - np.dot(X[i],beta0))**2 /(sigma**2))\n",
    "    \n",
    "    # initialize P,B\n",
    "    # P active set\n",
    "    # B beta's corresponding to columns of P\n",
    "    P = np.zeros((n,1))\n",
    "    P[:,0] = f.ravel()\n",
    "    B = np.zeros((p,1))\n",
    "    B[:,0] = beta0.ravel()\n",
    "    \n",
    "    # intialize coefficients of convex combinations\n",
    "    alpha = np.array([1]) \n",
    "    \n",
    "    for t in range(1,iter):\n",
    "        #solve LMO\n",
    "        g, beta_sol = sollmo(X,y,sigma,f)\n",
    "        #print(\"beta_sol\",beta_sol)\n",
    "        g = np.reshape(g,(n,1))\n",
    "        beta_sol = np.reshape(beta_sol,(p,1))\n",
    "        P = np.append(P,g,axis = 1)\n",
    "        B = np.append(B,beta_sol,axis = 1)\n",
    "        \n",
    "        #fully corrective step wrt current active set P\n",
    "        f, alpha = FW_FC(f,alpha,P,n)\n",
    "        \n",
    "        #prune P by deleting columns corresponding to zero alpha\n",
    "        P_prune = np.zeros((n,1))\n",
    "        B_prune = np.zeros((p,1))\n",
    "        alpha_prune = np.zeros((1,))\n",
    "        flag = 0\n",
    "        for i in range(len(P[0])):\n",
    "            if alpha[i] > 0:\n",
    "                if flag == 0:\n",
    "                    P_prune[:,0] = P[:,i].ravel()\n",
    "                    B_prune[:,0] = B[:,i].ravel()\n",
    "                    alpha_prune[0] = alpha[i]\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    P_prune = np.append(P_prune,np.reshape(P[:,i],(n,1)), axis = 1)\n",
    "                    alpha_prune = np.append(alpha_prune, alpha[i])\n",
    "                    B_prune = np.append(B_prune,np.reshape(B[:,i],(p,1)),axis = 1)\n",
    "        \n",
    "        P = P_prune\n",
    "        B = B_prune\n",
    "        alpha = np.reshape(alpha_prune/np.sum(alpha_prune), (len(P[0]),1))\n",
    "        \n",
    "        #record the change of neg-log likelihood function\n",
    "        temp = np.sum(np.log(1/f))\n",
    "        L_rec.append(temp)\n",
    "    return f, B, alpha, L_rec, temp\n",
    "\n",
    "\n",
    "def train_error(X,y,B,alpha):\n",
    "    beta_ave = np.matmul(B,alpha)\n",
    "    y = np.reshape(y,(len(y),1))\n",
    "    y_train = np.zeros((len(y), 1))\n",
    "    for i in range(len(y)):\n",
    "        y_train[i] = np.matmul(X[i],beta_ave)\n",
    "    y_train = np.reshape(y_train, (len(y),1))\n",
    "    return linalg.norm(y - y_train)**2/len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_sigma_rec_synthetic(n,iter, b1, b2,sigma):    \n",
    "    '''\n",
    "    return the neg-log likelihood as a function of sigma\n",
    "    synthesize its own data\n",
    "    test on a list of sigma\n",
    "    '''\n",
    "    \n",
    "    #set parameters\n",
    "    p =2    #number of components (currently we only consider 2 component)\n",
    "    probthre = 1e-2\n",
    "    pi = 0.5 # first componrnt has probability pi\n",
    "    \n",
    "    sigma1 = 2*sigma  # variance of 1st component\n",
    "    sigma2 = sigma      #variance of 2nd component\n",
    "    \n",
    "    \n",
    "    # synthesize two component data\n",
    "    b1 = np.reshape(b1,(2,1))\n",
    "    b2 = np.reshape(b2,(2,1))\n",
    "\n",
    "    X = np.zeros((n,2))\n",
    "    y = np.zeros((n,1))\n",
    "    for i in range(n):\n",
    "        X[i] = np.reshape([1,np.random.uniform(-1,3)],(1,2))\n",
    "        z = np.random.uniform(0,1)\n",
    "        if z < pi:\n",
    "            y[i] = np.dot(X[i],b1) + np.random.normal(0,sigma1)\n",
    "        else:\n",
    "            y[i] = np.dot(X[i],b2) + np.random.normal(0,sigma2)\n",
    "    \n",
    "    \n",
    "    sigma_list = np.arange(sigma2/2,sigma1*2,0.2)\n",
    "    \n",
    "    \n",
    "    L_sigma_rec = []\n",
    "    for sigma_est in sigma_list:\n",
    "        f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma_est)\n",
    "        L_sigma_rec.append(L_final)\n",
    "        \n",
    "    fig = plt.figure(figsize = (6,5))\n",
    "    plt.plot(L_sigma_rec);\n",
    "    plt.title(\"final likelihood over different sigma\");\n",
    "    return L_sigma_rec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with synthetic data\n",
    "def test(n,iter, b1, b2, b3,pi1,pi2,sigma,sigma_est):\n",
    "    # n : number of samples\n",
    "    # iter : number of iterations in Frank-Wofle method\n",
    "    \n",
    "    #set parameters\n",
    "    p =2    #number of components (currently we only consider 2 component)\n",
    "    #sigma = 0.8 # standard deviation\n",
    "    threprob = 0.02\n",
    "    #pi1 = 0.5 # first componrnt has probability pi\n",
    "    #pi2 = 0.25\n",
    "    \n",
    "    \n",
    "    #parameters for generating synthetic data\n",
    "    sigma1 = sigma  # variance of 1st component\n",
    "    sigma2 = sigma      #variance of 2nd component\n",
    "    sigma3 = sigma\n",
    "    \n",
    "    #sigma_est is what we use for Frank-Wofle method\n",
    "    \n",
    "    # synthesize two component data\n",
    "    b1 = np.reshape(b1,(2,1))\n",
    "    b2 = np.reshape(b2,(2,1))\n",
    "    b3 = np.reshape(b3,(2,1))\n",
    "\n",
    "    X = np.zeros((n,2))\n",
    "    y = np.zeros((n,1))\n",
    "    \n",
    "    # C denots the true class of each data point\n",
    "    C = np.zeros((n,1))\n",
    "    \n",
    "    np.random.seed(26)\n",
    "    for i in range(n):\n",
    "        X[i] = np.reshape([1,np.random.uniform(-1,3)],(1,2))\n",
    "        z = np.random.uniform(0,1)\n",
    "        if z < pi1:\n",
    "            y[i] = np.dot(X[i],b1) + np.random.normal(0,sigma1)\n",
    "            C[i] = 1\n",
    "        elif z < pi1 + pi2 :\n",
    "            y[i] = np.dot(X[i],b2) + np.random.normal(0,sigma2)\n",
    "            C[i] = 2\n",
    "        else:\n",
    "            y[i] = np.dot(X[i],b3) + np.random.normal(0,sigma3)\n",
    "            C[i] = 3\n",
    "            \n",
    "            \n",
    "    #test what sigma we use\n",
    "    #sigma_est = np.sqrt(pi* sigma1**2 + (1-pi)*sigma2**2)\n",
    "    \n",
    "    #run Frank-Wofle\n",
    "    f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma_est)\n",
    "    \n",
    "    \n",
    "    beta_ave = np.matmul(B,alpha)\n",
    "    print(\"averge beta is \", beta_ave)\n",
    "    print(\"training error is \",train_error(X,y,B,alpha) )\n",
    "\n",
    "    beta_ols = np.reshape(np.dot(np.matmul(linalg.inv(np.matmul(X.T,X)),X.T),y),(p,1))\n",
    "    print(\"beta_ols\",beta_ols)\n",
    "    #index = np.argwhere(alpha.ravel() == np.amax(alpha.ravel()))\n",
    "    \n",
    "    #plot\n",
    "    print(\"final neg log likelihood is \", L_final)\n",
    "    print(\"number of components is\", len(alpha))\n",
    "    print(\"only components with probability at least \", threprob, \" are shown below:\")\n",
    "    \n",
    "    fig_raw = plt.figure(figsize = (8,8))\n",
    "    plt.scatter(X[:,1],y,color = 'black',marker = 'o',label = 'Noisy data', facecolors = 'None');\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-2,4])\n",
    "    ax.set_ylim([-3,8])\n",
    "    plt.legend(loc=2, bbox_to_anchor=(0., -0.05),borderaxespad=0.);\n",
    "    plt.show();\n",
    "    \n",
    "    fig0 = plt.figure(figsize = (8,8))\n",
    "    for i in range(len(y)):\n",
    "        if C[i] == 1:\n",
    "            plt.scatter(X[i][1],y[i],color = 'red',marker = 'o',label = 'Class 1', facecolors = 'None');\n",
    "        elif C[i] == 2:\n",
    "            plt.scatter(X[i][1],y[i],color = 'blue',marker = 'o',label = 'Class 2', facecolors = 'None');\n",
    "        else:\n",
    "            plt.scatter(X[i][1],y[i],color = 'green',marker = 'o',label = 'Class 3', facecolors = 'None');\n",
    "            \n",
    "    t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-6)\n",
    "    #plt.plot(t,b1[0]+b1[1]*t,'r',t,b2[0]+b2[1]*t,'red')\n",
    "    i = 0\n",
    "    plt.plot(t,b1[0]+b1[1]*t, color = 'red',linewidth = pi1*8 )\n",
    "    plt.plot(t,b2[0]+b2[1]*t, color = 'blue',linewidth = pi2*8 )\n",
    "    if pi1 + pi2 < 1:\n",
    "        plt.plot(t,b3[0]+b3[1]*t, color = 'green',linewidth = (1-pi2-pi2)*8 )\n",
    "           \n",
    "            \n",
    "    #plt.plot(t,beta_ols[0]+beta_ols[1]*t,'green')  \n",
    "    if pi1 + pi2 <1:\n",
    "        custom_lines = [(Line2D([], [], color='red', marker='o',markerfacecolor = 'None', linestyle='None',linewidth = 8*pi1),Line2D([], [], color='red')),\n",
    "                        (Line2D([], [], color='blue', marker='o',markerfacecolor = 'None', linestyle='None',linewidth = 8*pi2),Line2D([], [], color='blue')),\n",
    "                         (Line2D([], [], color='green', marker='o',markerfacecolor = 'None', linestyle='None',linewidth = 8*(1-pi1-pi2)),Line2D([], [], color='green'))\n",
    "                        #Line2D([0], [0], color= 'red'# ),\n",
    "                        #Line2D([0], [0], color='black')\n",
    "                        #,Line2D([0], [0], color='green')#\n",
    "                        ]\n",
    "        plt.legend(custom_lines, ['y = %.1f + %.1f x with probility %.2f' %(b1[0], b1[1], pi1), #,'True mixture'# \n",
    "                                  'y = %.1f + %.1f x with probility %.2f' %(b2[0], b2[1], pi2),\n",
    "                                  'y = %.1f + %.1f x with probility %.2f' %(b3[0], b3[1], 1-pi1-pi2),\n",
    "                                   #'NPMLE component'#, 'OLS'#\n",
    "                                 ],loc = 2,bbox_to_anchor=(0., -0.05),borderaxespad=0.);\n",
    "    else:\n",
    "        custom_lines = [(Line2D([], [], color='red', marker='o',markerfacecolor = 'None', linestyle='None',linewidth = 8*pi1),Line2D([], [], color='red')),\n",
    "                        (Line2D([], [], color='blue', marker='o',markerfacecolor = 'None', linestyle='None',linewidth = 8*pi2),Line2D([], [], color='blue')),\n",
    "                    \n",
    "                        #Line2D([0], [0], color= 'red'# ),\n",
    "                        #Line2D([0], [0], color='black')\n",
    "                        #,Line2D([0], [0], color='green')#\n",
    "                        ]\n",
    "        plt.legend(custom_lines, ['y = %.1f + %.1f x with probility %.2f' %(b1[0], b1[1], pi1), #,'True mixture'# \n",
    "                                  'y = %.1f + %.1f x with probility %.2f' %(b2[0], b2[1], pi2),\n",
    "                                \n",
    "                                   #'NPMLE component'#, 'OLS'#\n",
    "                                 ],loc=2,bbox_to_anchor=(0., -0.05),borderaxespad=0.);\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-2,4])\n",
    "    ax.set_ylim([-3,8])\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "    \n",
    "    fig1 = plt.figure(figsize = (8,8))\n",
    "\n",
    "    t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-6)\n",
    "    \n",
    "    \n",
    "    #plt.plot(t,b1[0]+b1[1]*t,'r',t,b2[0]+b2[1]*t,'red')\n",
    "    \n",
    "    N = len(alpha)\n",
    "    \n",
    "    RGB_tuples = [(240,163,255),(0,117,220),(153,63,0),(76,0,92),(0,92,49),\n",
    "    (43,206,72),(255,204,153),(128,128,128),(148,255,181),(143,124,0),(157,204,0),\n",
    "    (194,0,136),(0,51,128),(255,164,5),(255,168,187),(66,102,0),(255,0,16),(94,241,242),(0,153,143),\n",
    "    ( 224,255,102),(116,10,255),(153,0,0),(255,255,128),(255,255,0),(25,25,25),(255,80,5)]\n",
    "    \n",
    "    component_plot = []\n",
    "    component_color = []\n",
    "    \n",
    "    temp = 0\n",
    "    index_sort = np.argsort(-np.reshape(alpha,(len(alpha),)))\n",
    "    for i in index_sort:\n",
    "        b = B[:,i]\n",
    "        if alpha[i] >threprob:\n",
    "            component_plot.append(i)\n",
    "            component_color.append(temp)\n",
    "            plt.plot(t,b[0]+b[1]*t, color = tuple( np.array(RGB_tuples[temp])/255),linewidth = alpha[i][0]*8 ,label = 'y = %.4f + %.4f x with probility %.2f' %(b[0], b[1], alpha[i]))\n",
    "            temp = temp + 1\n",
    "            print(\"coefficients\", b, \"with probability\", alpha[i])\n",
    "    \n",
    "    # we ONLY do clustering based on plotted components, i.e. components with high probability (>threprob)\n",
    "    C_cluster = np.zeros((n,1))\n",
    "    for i in range(len(y)):\n",
    "        prob = np.zeros((N,1))\n",
    "        for j in component_plot:\n",
    "            prob[j] = alpha[j] * np.exp(-0.5*(y[i] - np.dot(X[i],B[:,j]))**2 /(sigma**2))\n",
    "        C_cluster[i] = np.argmax(prob)\n",
    "        plt.scatter(X[i][1],y[i],color = tuple(np.array(RGB_tuples[component_color[component_plot.index(C_cluster[i])]])/255) ,marker = 'o', facecolors = 'None'); \n",
    "            \n",
    "    #plt.plot(t,beta_ols[0]+beta_ols[1]*t,'green')  \n",
    "    \n",
    "    #custom_lines = [Line2D([], [], color='blue', marker='o',markerfacecolor = 'None', linestyle='None'),\n",
    "                    #Line2D([0], [0], color= 'red'# ),\n",
    "                    #Line2D([0], [0], color='black')\n",
    "                    #,Line2D([0], [0], color='green')#\n",
    "                    #,]\n",
    "    #plt.legend(custom_lines, ['Noisy data'#,'True mixture'# \n",
    "                            #  , 'NPMLE component'#, 'OLS'#\n",
    "                            # ],loc=0);\n",
    "    plt.legend(bbox_to_anchor=(0., -0.05), loc=2, borderaxespad=0.)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-2,4])\n",
    "    ax.set_ylim([-3,8])\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "    #plot Hellinger distance\n",
    "    fig2 = plt.figure(figsize = (20,3))\n",
    "    x_list = [-3,-1,1,3,5] #List of x values\n",
    "    i = 0\n",
    "    \n",
    "    for i in range(len(x_list)):\n",
    "        x = x_list[i]\n",
    "        y = np.linspace(- 15, 15, 100)\n",
    "           \n",
    "        #calculate difference of suqre root of density functions\n",
    "        dist_fit = lambda y: (np.sqrt(0.5*scipy.stats.norm.pdf(y-(b1[0]+b1[1]*x), 0, sigma)+0.5*scipy.stats.norm.pdf(y-(b1[0]+b1[1]*x),0, sigma)) \\\n",
    "        - np.sqrt(sum(alpha[i]*scipy.stats.norm.pdf( y - (B[0,i]+B[1,i]*x), 0, sigma) for i in range(len(alpha)))))**2\n",
    "        \n",
    "        print(\"Fix x = %.1f, squared Hellinger distance for NPMLE is %.5f\" % (x, quad(dist_fit, -np.inf, np.inf)[0]))\n",
    "\n",
    "        \n",
    "        plt.subplot(1,len(x_list),i+1)\n",
    "        plt.plot(y,pi1*scipy.stats.norm.pdf(y - (b1[0]+b1[1]*x), 0, sigma)+pi2*scipy.stats.norm.pdf(y-(b2[0]+b2[1]*x),0, sigma)+(1-pi1-pi2)*scipy.stats.norm.pdf(y-(b3[0]+b3[1]*x),0, sigma),'red',label = 'True distribution')\n",
    "        plt.plot(y, sum(alpha[i]*scipy.stats.norm.pdf( y-(B[0,i]+B[1,i]*x), 0, sigma) for i in range(len(alpha))),'black',label = 'NPMLE distribution')\n",
    "        plt.title(\"x = %.1f\"%x)\n",
    "    custom_lines = [\n",
    "                Line2D([0], [0], color= 'red'),\n",
    "                Line2D([0], [0], color='black'),\n",
    "                #Line2D([0], [0], color='green')#\n",
    "        ]\n",
    "    plt.legend(custom_lines, ['True mixture', 'Fitted mixture'#, 'OLS'#\n",
    "                             ], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "    fig3 = plt.figure(figsize = (6,5))\n",
    "    plt.plot(L_rec);plt.title(\"neg-log likelihood over iterations\");\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Synthetic Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#colorful\n",
    "test(5000,50,(1,1),(4,-1),(-1,0.5),0.5,0.5,sigma = 0.8,sigma_est=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorful\n",
    "test(300,50,(0,1),(5,1),(0,1),0.5,0.5,sigma = 1,sigma_est = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colorful\n",
    "test(500,50,(1,1.5),(3,-1),(-1,0.5),0.3,0.3,sigma = 0.5,sigma_est = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sigma Choice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "p =2    #number of components (currently we only consider 2 component)\n",
    "sigma = 0.2 # standard deviation\n",
    "probthre = 1e-2\n",
    "pi = 0.5 # first componrnt has probability pi\n",
    "\n",
    "sigma1 = sigma  # variance of 1st component\n",
    "sigma2 = sigma      #variance of 2nd component\n",
    "\n",
    "# synthesize two component data\n",
    "b1 = np.reshape([1,1],(2,1))\n",
    "b2 = np.reshape([4,-1],(2,1))\n",
    "\n",
    "X = np.zeros((n,2))\n",
    "y = np.zeros((n,1))\n",
    "for i in range(n):\n",
    "    X[i] = np.reshape([1,np.random.uniform(-1,3)],(1,2))\n",
    "    z = np.random.uniform(0,1)\n",
    "    if z < pi:\n",
    "        y[i] = np.dot(X[i],b1) + np.random.normal(0,sigma1)\n",
    "    else:\n",
    "        y[i] = np.dot(X[i],b2) + np.random.normal(0,sigma2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_max = np.sqrt(stats.variance(np.reshape(y, (len(y),))))\n",
    "sigma_min = 0.1\n",
    "sigma_list = np.sqrt(np.arange(sigma_min**2, sigma_max**2, 0.06**2))\n",
    "number = len(X)\n",
    "#random permutation to shuffle data\n",
    "index = np.random.permutation(number)\n",
    "\n",
    "X_shuffled = X[index]\n",
    "y_shuffled = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec_synthetic(500,300, (1,1), (4,-1),0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5 fold cross validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec,train_error_sigma_rec, test_error_sigma_rec = L_sigma(X_shuffled[:120],y_shuffled[:120],X_shuffled[120:150],y_shuffled[120:150],sigma_list)\n",
    "L_sigma_rec2,train_error_sigma_rec2, test_error_sigma_rec2 = L_sigma(X_shuffled[30:150],y_shuffled[30:150],X_shuffled[:30],y_shuffled[:30],sigma_list)\n",
    "L_sigma_rec3,train_error_sigma_rec3, test_error_sigma_rec3 = L_sigma(np.append(X_shuffled[:30], X_shuffled[60:150],axis = 0),np.append(y_shuffled[:30], y_shuffled[60:150],axis = 0),X_shuffled[30:60],y_shuffled[30:60],sigma_list)\n",
    "L_sigma_rec4,train_error_sigma_rec4, test_error_sigma_rec4 = L_sigma(np.append(X_shuffled[:60], X_shuffled[90:150],axis = 0),np.append(y_shuffled[:60], y_shuffled[90:150],axis = 0),X_shuffled[60:90],y_shuffled[60:90],sigma_list)\n",
    "L_sigma_rec5,train_error_sigma_rec5, test_error_sigma_rec5 = L_sigma(np.append(X_shuffled[:90], X_shuffled[120:150],axis = 0),np.append(y_shuffled[:90], y_shuffled[120:150],axis = 0),X_shuffled[90:120],y_shuffled[90:120],sigma_list)\n",
    "L_sigma_rec_CV = np.zeros((len(sigma_list),1))\n",
    "L_sigma_rec_CV = np.array(L_sigma_rec)+np.array(L_sigma_rec2)+ np.array(L_sigma_rec3)+ np.array(L_sigma_rec4)+ np.array(L_sigma_rec5)\n",
    "train_error_sigma_rec_CV = np.zeros((len(sigma_list),1))\n",
    "train_error_sigma_rec_CV = np.array(train_error_sigma_rec) + np.array(train_error_sigma_rec2) + np.array(train_error_sigma_rec3) + np.array(train_error_sigma_rec4) + np.array(train_error_sigma_rec5)\n",
    "train_error_sigma_rec_CV = train_error_sigma_rec_CV/5\n",
    "fig1 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, L_sigma_rec_CV);plt.title(\"5-fold CV neg-log likelihood\");\n",
    "    \n",
    "fig2 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, train_error_sigma_rec_CV);plt.title(\"5-fold CV taining error\");\n",
    "    \n",
    "fig3 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, test_error_sigma_rec_CV);plt.title(\"5-fold CV validation error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hellinger risk scaling wrt n__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with synthetic data\n",
    "def hellinger_risk(n,num,iter, b1, b2, b3,pi1,pi2,sigma,sigma_est):\n",
    "    '''\n",
    "    Return the average risk on #num random experiments\n",
    "    \n",
    "    '''\n",
    "\n",
    "    hellinger_rec = []\n",
    "    \n",
    "    for j in range(num):\n",
    "        \n",
    "        p =2    #number of components (currently we only consider 2 component)\n",
    "        #sigma = 0.8 # standard deviation\n",
    "        threprob = 0.02\n",
    "        #pi1 = 0.5 # first componrnt has probability pi\n",
    "        #pi2 = 0.25\n",
    "\n",
    "\n",
    "        #parameters for generating synthetic data\n",
    "        sigma1 = sigma  # variance of 1st component\n",
    "        sigma2 = sigma      #variance of 2nd component\n",
    "        sigma3 = sigma\n",
    "\n",
    "        #sigma_est is what we use for Frank-Wofle method\n",
    "\n",
    "        # synthesize two component data\n",
    "        b1 = np.reshape(b1,(2,1))\n",
    "        b2 = np.reshape(b2,(2,1))\n",
    "        b3 = np.reshape(b3,(2,1))\n",
    "\n",
    "        X = np.zeros((n,2))\n",
    "        y = np.zeros((n,1))\n",
    "\n",
    "        # C denots the true class of each data point\n",
    "        C = np.zeros((n,1))\n",
    "\n",
    "        for i in range(n):\n",
    "            X[i] = np.reshape([1,np.random.uniform(-1,3)],(1,2))\n",
    "            z = np.random.uniform(0,1)\n",
    "            if z < pi1:\n",
    "                y[i] = np.dot(X[i],b1) + np.random.normal(0,sigma1)\n",
    "                C[i] = 1\n",
    "            elif z < pi1 + pi2 :\n",
    "                y[i] = np.dot(X[i],b2) + np.random.normal(0,sigma2)\n",
    "                C[i] = 2\n",
    "            else:\n",
    "                y[i] = np.dot(X[i],b3) + np.random.normal(0,sigma3)\n",
    "                C[i] = 3\n",
    "\n",
    "        f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma_est)\n",
    "        hellinger = 0\n",
    "        for i in range(n):\n",
    "            x = X[i][1]           \n",
    "\n",
    "            #calculate difference of suqre root of density functions\n",
    "            dist_fit = lambda y: (np.sqrt(0.5*scipy.stats.norm.pdf(y-(b1[0]+b1[1]*x), 0, sigma)+0.5*scipy.stats.norm.pdf(y-(b1[0]+b1[1]*x),0, sigma)) \\\n",
    "            - np.sqrt(sum(alpha[i]*scipy.stats.norm.pdf( y - (B[0,i]+B[1,i]*x), 0, sigma) for i in range(len(alpha)))))**2\n",
    "\n",
    "            hellinger = hellinger + quad(dist_fit, -np.inf, np.inf)[0]\n",
    "        hellinger_rec.append(hellinger/n)\n",
    "    return hellinger_rec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hellinger_rec = hellinger_risk(50,20,30,(1,1),(4,-1),(-1,0.5),0.5,0.5,sigma = 0.8,sigma_est=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/software/sl-7.x86_64/modules/langs/python/3.5/lib/python3.5/site-packages/scipy/integrate/quadpack.py:364: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  warnings.warn(msg, IntegrationWarning)\n"
     ]
    }
   ],
   "source": [
    "hellinger_n_rec = []\n",
    "for n in np.arange(5,5000,50):\n",
    "    hellinger_n_rec.append(np.sum(hellinger_risk(50,num,20,(1,1),(10,-1),(-1,0.5),0.5,0.5,sigma = 0.3,sigma_est=0.3))/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.arange(5,5000,50)\n",
    "np.divide(z,np.log(z)**(3.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(z,np.log(z)**(3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hellinger_n_rec2 = []\n",
    "for n in np.arange(500,1000,50):\n",
    "    hellinger_n_rec2.append(np.sum(hellinger_risk(50,num,20,(1,1),(4,-1),(-1,0.5),0.5,0.5,sigma = 0.3,sigma_est=0.3))/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Continuous Measure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "x = 0\n",
    "sigma = 0.3\n",
    "meanb1 = [1,1]\n",
    "covb1 = [[0.01,0],[0,0.2]]\n",
    "meanb2 = [5,2]\n",
    "covb2 = [[0.01,0],[0,0.2]]\n",
    "\n",
    "from scipy import integrate\n",
    "\n",
    "# density function under continuous measure\n",
    "def func_xy(x,y):\n",
    "    func = lambda b,k: scipy.stats.norm.pdf(y - (b+k*x), 0, sigma)*(0.5*scipy.stats.norm.pdf(b, meanb1[0], np.sqrt(covb1[0][0]))*\\\n",
    "                                                            scipy.stats.norm.pdf(k, meanb1[1], np.sqrt(covb1[1][1]))+ 0.5*scipy.stats.norm.pdf(b, meanb2[0], np.sqrt(covb2[0][0]))\\\n",
    "                                                           *scipy.stats.norm.pdf(k, meanb2[1], np.sqrt(covb2[1][1])))\n",
    "    return func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function with synthetic data\n",
    "def test_continuous(n,iter):\n",
    "    # n : number of samples\n",
    "    # iter : number of iterations in Frank-Wofle method\n",
    "    \n",
    "    #set parameters\n",
    "    p =2    #number of components (currently we only consider 2 component)\n",
    "    sigma = 0.3 # standard deviation\n",
    "    threprob = 0.02   \n",
    "    \n",
    "    #sigma_est is what we use for Frank-Wofle method\n",
    "    #one guess is to use the std of y\n",
    "    sigma_est = sigma\n",
    "    \n",
    "    X = np.zeros((n,2))\n",
    "    y = np.zeros((n,1))\n",
    "    \n",
    "    np.random.seed(26)\n",
    "    for i in range(n):\n",
    "        b_pi = np.random.uniform(0,1)\n",
    "        \n",
    "        X[i] = np.reshape([1,np.random.uniform(-1,3)],(1,2))\n",
    "        meanb1 = [1,1]\n",
    "        covb1 = [[0.01,0],[0,0.2]]\n",
    "        meanb2 = [5,2]\n",
    "        covb2 = [[0.01,0],[0,0.2]]\n",
    "        b1 = np.reshape(np.random.multivariate_normal(meanb1,covb1,1),(2,1))\n",
    "        b2 = np.reshape(np.random.multivariate_normal(meanb2,covb2,1),(2,1))\n",
    "\n",
    "        '''\n",
    "    \n",
    "        b1 = np.random.beta(2,6,size = (2,1))\n",
    "        b2 = np.array([[1],[0.5]])+np.random.beta(2,2,size = (2,1))\n",
    "        '''\n",
    "        if b_pi < 0.5:\n",
    "            b = b1\n",
    "        else:\n",
    "            b = b2\n",
    "        y[i] = np.dot(X[i],b) + np.random.normal(0,sigma)\n",
    "    \n",
    "    \n",
    "    #run Frank-Wofle\n",
    "    f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma_est)\n",
    "    \n",
    "    \n",
    "    beta_ave = np.matmul(B,alpha)\n",
    "    print(\"averge beta is \", beta_ave)\n",
    "    print(\"training error is \",train_error(X,y,B,alpha) )\n",
    "\n",
    "    beta_ols = np.reshape(np.dot(np.matmul(linalg.inv(np.matmul(X.T,X)),X.T),y),(p,1))\n",
    "    print(\"beta_ols\",beta_ols)\n",
    "    #index = np.argwhere(alpha.ravel() == np.amax(alpha.ravel()))\n",
    "    \n",
    "    #plot\n",
    "    print(\"final neg log likelihood is \", L_final)\n",
    "    print(\"number of components is\", len(alpha))\n",
    "    print(\"only components with probability at least \", threprob, \" are shown below:\")\n",
    "    \n",
    "    fig_raw = plt.figure(figsize = (8,8))\n",
    "    for i in range(len(y)):\n",
    "         plt.scatter(X[i][1],y[i],color = 'black',marker = 'o', facecolors = 'None');\n",
    "    \n",
    "    \n",
    "    fig1 = plt.figure(figsize = (8,8))\n",
    "\n",
    "    t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-6)\n",
    "    \n",
    "    \n",
    "    #plt.plot(t,b1[0]+b1[1]*t,'r',t,b2[0]+b2[1]*t,'red')\n",
    "    \n",
    "    N = len(alpha)\n",
    "    \n",
    "    RGB_tuples = [(240,163,255),(0,117,220),(153,63,0),(76,0,92),(0,92,49),\n",
    "    (43,206,72),(255,204,153),(128,128,128),(148,255,181),(143,124,0),(157,204,0),\n",
    "    (194,0,136),(0,51,128),(255,164,5),(255,168,187),(66,102,0),(255,0,16),(94,241,242),(0,153,143),\n",
    "    ( 224,255,102),(116,10,255),(153,0,0),(255,255,128),(255,255,0),(25,25,25),(255,80,5)]\n",
    "    \n",
    "    component_plot = []\n",
    "    component_color = []\n",
    "    \n",
    "    temp = 0\n",
    "    index_sorted = np.argsort(-np.reshape(alpha,(len(alpha),)))\n",
    "    for i in index_sorted:\n",
    "        b = B[:,i]\n",
    "        if alpha[i] >threprob:\n",
    "            component_plot.append(i)\n",
    "            component_color.append(temp)\n",
    "            plt.plot(t,b[0]+b[1]*t, color = tuple( np.array(RGB_tuples[temp])/255),linewidth = alpha[i][0]*8,label = 'y = %7f + %.7f x with prob %.2f' %(b[0], b[1], alpha[i]) )\n",
    "            temp = temp + 1\n",
    "            print(\"coefficients\", b, \"with probability\", alpha[i])\n",
    "    \n",
    "    # we ONLY do clustering based on plotted components, i.e. components with high probability (>threprob)\n",
    "    C_cluster = np.zeros((n,1))\n",
    "    for i in range(len(y)):\n",
    "        prob = np.zeros((N,1))\n",
    "        for j in component_plot:\n",
    "            prob[j] = alpha[j] * np.exp(-0.5*(y[i] - np.dot(X[i],B[:,j]))**2 /(sigma**2))\n",
    "        C_cluster[i] = np.argmax(prob)\n",
    "        plt.scatter(X[i][1],y[i],color = tuple(np.array(RGB_tuples[component_color[component_plot.index(C_cluster[i])]])/255) ,marker = 'o', facecolors = 'None'); \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=9, borderaxespad=0.)     \n",
    "    plt.show();\n",
    "    \n",
    "    #plot Hellinger distance\n",
    "    fig2 = plt.figure(figsize = (20,3))\n",
    "    x_list = [-3,-1,1,3,5] #List of x values\n",
    "    i = 0\n",
    "    \n",
    "    for i in range(len(x_list)):\n",
    "        x = x_list[i]\n",
    "        y = np.linspace(- 15, 15, 100)\n",
    "        z = np.zeros(len(np.linspace(- 15, 15, 100)))\n",
    "        for j in range(len(z)):\n",
    "            z[j] = integrate.dblquad(func_xy(x,y[j]),-np.inf,np.inf,-np.inf,np.inf)[0]\n",
    "        plt.subplot(1,len(x_list),i+1)\n",
    "        plt.plot(y,z,'red',label = 'True distribution')\n",
    "        plt.plot(y, sum(alpha[i]*scipy.stats.norm.pdf( y-(B[0,i]+B[1,i]*x), 0, sigma) for i in range(len(alpha))),'black',label = 'NPMLE distribution')\n",
    "        #plt.plot(y, scipy.stats.norm.pdf(y-(beta_ols[0]+beta_ols[1]*x), 0, sigma),'green',label = 'OLS distribution')  \n",
    "        #plt.xlabel('y')\n",
    "        #plt.ylabel('pdf')\n",
    "        plt.title(\"x = %.1f\"%x)\n",
    "    custom_lines = [\n",
    "                Line2D([0], [0], color= 'red'),\n",
    "                Line2D([0], [0], color='black'),\n",
    "                #Line2D([0], [0], color='green')#\n",
    "        ]\n",
    "    plt.legend(custom_lines, ['True mixture', 'Fitted mixture'#, 'OLS'#\n",
    "                             ], loc = (1.05,1))\n",
    "    plt.show()\n",
    "    \n",
    "    fig3 = plt.figure(figsize = (6,5))\n",
    "    plt.plot(L_rec);plt.title(\"neg-log likelihood over iterations\");\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_continuous(500,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tone perception data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read tonedata into file\n",
    "with open('tonedata.csv', newline='') as csvfile:\n",
    "    data = np.array(list(csv.reader(csvfile)))\n",
    "    data = data[1:]\n",
    "dataf = data.astype(np.float)\n",
    "n = np.shape(dataf)[0]\n",
    "ones = np.ones((n,1))\n",
    "X = np.concatenate((ones, np.reshape(dataf[:,1],(n,1))), axis = 1)\n",
    "y = np.reshape(dataf[:,2],(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 200\n",
    "threprob = 0.02\n",
    "\n",
    "#Use Frank-Wofle with an estimated sigma\n",
    "sigma = 0.03\n",
    "f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma)\n",
    "\n",
    "\n",
    "#beta_ols = np.reshape(np.dot(np.matmul(linalg.inv(np.matmul(X.T,X)),X.T),y),(p,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "print(\"final neg log likelihood is \", L_final)\n",
    "print(\"number of components is\", len(alpha))\n",
    "print(\"only components with probability at least \", threprob, \" are shown below:\")\n",
    "\n",
    "fig1 = plt.figure(figsize = (8,8))\n",
    "plt.scatter(X[:,1],y,color = 'black',marker = 'o',label = 'Noisy data', facecolors = 'None');\n",
    "t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-6)\n",
    "#plt.plot(t,b1[0]+b1[1]*t,'r',t,b2[0]+b2[1]*t,'red')\n",
    "i = 0\n",
    "\n",
    "index_sorted = np.argsort(-np.reshape(alpha,(len(alpha),)))\n",
    "for i in index_sorted:\n",
    "    b = B[:,i]\n",
    "    if alpha[i] >threprob:\n",
    "        plt.plot(t,b[0]+b[1]*t, color = str((1-alpha[i][0])/100),linewidth = alpha[i][0]*8 ,label = 'y = %.4f + %.4f x with prob %.2f' %(b[0], b[1], alpha[i]) )\n",
    "        print(\"coefficients\", b, \"with probability\", alpha[i])\n",
    "#plt.plot(t,beta_ols[0]+beta_ols[1]*t,'green')  \n",
    "#plt.legend(custom_lines, ['Noisy data'#,'True mixture'# \n",
    "                         # , 'NPMLE component'#, 'OLS'#\n",
    "                         #],loc=2);\n",
    "plt.legend(loc=9, bbox_to_anchor=(1.05, 1),borderaxespad=0.) \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a range of candidate sigma values\n",
    "sigma_max = np.sqrt(stats.variance(np.reshape(y, (len(y),))))\n",
    "sigma_min = 0.06\n",
    "sigma_list = np.sqrt(np.arange(sigma_min**2, sigma_max**2, sigma_min**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_sigma(X,y,X_test,y_test,sigma_list):\n",
    "    '''\n",
    "    test X,y\n",
    "    '''\n",
    "    L_sigma_rec = []\n",
    "    train_error_sigma_rec = []\n",
    "    test_error_sigma_rec = []\n",
    "        \n",
    "    iter = 200\n",
    "    threprob = 1e-2\n",
    "    y = np.reshape(y,(len(y),1))\n",
    "    y_test = np.reshape(y_test,(len(y_test),1))\n",
    "    \n",
    "    for sigma in sigma_list:\n",
    "        f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma)\n",
    "        L_sigma_rec.append(L_final)\n",
    "        \n",
    "        beta_ave = np.matmul(B,alpha)\n",
    "        \n",
    "        y_train = np.zeros((len(y), 1))\n",
    "        for i in range(len(y)):\n",
    "            y_train[i] = np.matmul(X[i],beta_ave)\n",
    "        y_train = np.reshape(y_train, (len(y),1))\n",
    "        train_error_sigma_rec.append(linalg.norm(y_train - y)**2/len(X))\n",
    "        \n",
    "        y_test_pred = np.zeros((len(y_test), 1))\n",
    "        for i in range(len(y_test)):\n",
    "            y_test_pred[i] = np.matmul(X[i],beta_ave)\n",
    "        y_test_pred = np.reshape(y_test_pred, (len(y_test),1))\n",
    "        test_error_sigma_rec.append(linalg.norm(y_test - y_test_pred)**2/len(X))\n",
    "    \n",
    "    fig1 = plt.figure(figsize = (6,5))\n",
    "    plt.plot(sigma_list, L_sigma_rec);\n",
    "    \n",
    "    fig2 = plt.figure(figsize = (6,5))\n",
    "    plt.plot(sigma_list, train_error_sigma_rec);\n",
    "    \n",
    "    fig3 = plt.figure(figsize = (6,5))\n",
    "    plt.plot(sigma_list, test_error_sigma_rec)\n",
    "    \n",
    "    return L_sigma_rec,train_error_sigma_rec, test_error_sigma_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a range of candidate sigma values\n",
    "sigma_max = np.sqrt(stats.variance(np.reshape(y, (len(y),))))\n",
    "sigma_min = 0.03\n",
    "sigma_list = np.sqrt(np.arange(sigma_min**2, sigma_max**2, 0.06**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = np.random.choice(len(y), 10)\n",
    "L_sigma_rec = L_sigma(X[subset],y[subset],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = len(X)\n",
    "#random permutation to shuffle data\n",
    "index = np.random.permutation(number)\n",
    "\n",
    "X_shuffled = X[index]\n",
    "y_shuffled = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec,train_error_sigma_rec, test_error_sigma_rec = L_sigma(X_shuffled[:40],y_shuffled[:40],X_shuffled[40:50],y_shuffled[40:50],sigma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5-Fold Cross Validation for Tone Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec,train_error_sigma_rec, test_error_sigma_rec = L_sigma(X_shuffled[:120],y_shuffled[:120],X_shuffled[120:150],y_shuffled[120:150],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec2,train_error_sigma_rec2, test_error_sigma_rec2 = L_sigma(X_shuffled[30:150],y_shuffled[30:150],X_shuffled[:30],y_shuffled[:30],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec3,train_error_sigma_rec3, test_error_sigma_rec3 = L_sigma(np.append(X_shuffled[:30], X_shuffled[60:150],axis = 0),np.append(y_shuffled[:30], y_shuffled[60:150],axis = 0),X_shuffled[30:60],y_shuffled[30:60],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec4,train_error_sigma_rec4, test_error_sigma_rec4 = L_sigma(np.append(X_shuffled[:60], X_shuffled[90:150],axis = 0),np.append(y_shuffled[:60], y_shuffled[90:150],axis = 0),X_shuffled[60:90],y_shuffled[60:90],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec5,train_error_sigma_rec5, test_error_sigma_rec5 = L_sigma(np.append(X_shuffled[:90], X_shuffled[120:150],axis = 0),np.append(y_shuffled[:90], y_shuffled[120:150],axis = 0),X_shuffled[90:120],y_shuffled[90:120],sigma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_sigma_rec_CV = np.zeros((len(sigma_list),1))\n",
    "L_sigma_rec_CV = np.array(L_sigma_rec)+np.array(L_sigma_rec2)+ np.array(L_sigma_rec3)+ np.array(L_sigma_rec4)+ np.array(L_sigma_rec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_sigma_rec_CV = np.zeros((len(sigma_list),1))\n",
    "train_error_sigma_rec_CV = np.array(train_error_sigma_rec) + np.array(train_error_sigma_rec2) + np.array(train_error_sigma_rec3) + np.array(train_error_sigma_rec4) + np.array(train_error_sigma_rec5)\n",
    "train_error_sigma_rec_CV = train_error_sigma_rec_CV/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, L_sigma_rec_CV);plt.title(\"5-fold CV neg-log likelihood\");\n",
    "    \n",
    "fig2 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, train_error_sigma_rec_CV);plt.title(\"5-fold CV taining error\");\n",
    "    \n",
    "fig3 = plt.figure(figsize = (6,5))\n",
    "plt.plot(sigma_list, test_error_sigma_rec_CV);plt.title(\"5-fold CV validation error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GDP-CO2 Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read gdp-co2data into file\n",
    "with open('gdp-co2.csv', newline='') as csvfile:\n",
    "    data = np.array(list(csv.reader(csvfile)))\n",
    "dataf = data[:,1:4].astype(np.float)\n",
    "n = np.shape(dataf)[0]\n",
    "ones = np.ones((n,1))\n",
    "X = np.concatenate((ones, np.reshape(dataf[:,1]/dataf[:,0]*100,(n,1))), axis = 1)\n",
    "y = np.reshape(dataf[:,2]/dataf[:,0]*1e+6,(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 200\n",
    "threprob = 1e-2\n",
    "\n",
    "#Use Frank-Wofle with an estimated sigma\n",
    "sigma = 2\n",
    "f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma)\n",
    "\n",
    "##########IMPORTANT subproblem initializes with beta = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "print(\"final neg log likelihood is \", L_final)\n",
    "print(\"number of components is\", len(alpha))\n",
    "print(\"only components with probability at least \", threprob, \" are shown below:\")\n",
    "\n",
    "fig1 = plt.figure(figsize = (8,8))\n",
    "plt.scatter(X[:,1],y,color = 'blue',marker = 'o',label = 'Noisy data', facecolors = 'None');\n",
    "t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-2)\n",
    "i = 0\n",
    "for i in range(len(alpha)):\n",
    "    b = B[:,i]\n",
    "    if alpha[i] >threprob:\n",
    "        plt.plot(t,b[0]+b[1]*t, color = str((1-alpha[i][0])/100),linewidth = alpha[i][0]*8 )\n",
    "        print(\"coefficients\", b, \"with probability\", alpha[i]) \n",
    "custom_lines = [Line2D([], [], color='blue', marker='o',markerfacecolor = 'None', linestyle='None'),\n",
    "                Line2D([0], [0], color='black')\n",
    "                ,]\n",
    "plt.legend(custom_lines, ['Noisy data'\n",
    "                          , 'NPMLE component'\n",
    "                         ],loc=9);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Aphids Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read aphids into file\n",
    "with open('aphids.csv', newline='') as csvfile:\n",
    "    data = np.array(list(csv.reader(csvfile)))\n",
    "dataf = data[1:,1:3].astype(np.float)\n",
    "n = np.shape(dataf)[0]\n",
    "ones = np.ones((n,1))\n",
    "X = np.concatenate((ones, np.reshape(dataf[:,0],(n,1))), axis = 1)\n",
    "y = np.reshape(dataf[:,1],(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_aphids(sigma):\n",
    "    iter = 200\n",
    "    #Use Frank-Wofle with an estimated sigma\n",
    "    #sigma = 3.3\n",
    "    f, B, alpha, L_rec, L_final = NPMLE_FW(X,y,iter,sigma)\n",
    "    threprob = 0.02\n",
    "    #plot\n",
    "    print(\"final neg log likelihood is \", L_final)\n",
    "    print(\"number of components is\", len(alpha))\n",
    "    print(\"only components with probability at least \", threprob, \" are shown below:\")\n",
    "\n",
    "    fig1 = plt.figure(figsize = (8,8))\n",
    "    plt.scatter(X[:,1],y,color = 'blue',marker = 'o',label = 'Noisy data', facecolors = 'None');\n",
    "    t = np.arange(np.amin(X[:,1])-0.5,np.amax(X[:,1])+0.5,1e-2)\n",
    "    i = 0\n",
    "    index_sorted = np.argsort(-np.reshape(alpha,(len(alpha),)))\n",
    "    for i in index_sorted:\n",
    "        b = B[:,i]\n",
    "        if alpha[i] >threprob:\n",
    "            plt.plot(t,b[0]+b[1]*t, color = str((1-alpha[i][0])/100),linewidth = alpha[i][0]*8 ,label = 'y = %.4f + %.4f x with prob %.2f' %(b[0], b[1], alpha[i]) )\n",
    "            print(\"coefficients\", b, \"with probability\", alpha[i]) \n",
    "    custom_lines = [Line2D([], [], color='blue', marker='o',markerfacecolor = 'None', linestyle='None'),\n",
    "                    Line2D([0], [0], color='black')\n",
    "                    ,]\n",
    "    #plt.legend(custom_lines, ['Noisy data'\n",
    "                 #             , 'NPMLE component'\n",
    "                  #           ],loc=0);\n",
    "    plt.legend(loc=9, bbox_to_anchor=(1.05, 1),borderaxespad=0.) \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sigma in np.arange(1,3,0.1):\n",
    "    print(\"**************************\",sigma)\n",
    "    test_aphids(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
