#A standard dataset for illustrating continuous by continuous interactions in linear regression is the hsbdemo data (see e.g., https://stats.idre.ucla.edu/r/faq/how-can-i-explain-a-continuous-by-continuous-interaction/ or http://web.pdx.edu/~joel8/resources/ConceptualPresentationResources/ContinuousByContinousInteractions_walkthrough_v2.pdf) I was wondering what our EM gives and how it compares with the results of linear regressions for this dataset. Let me first fit the usual linear models.
#Open the hsbdemo dataset
#It is in an .xlsx file
library(openxlsx)
dd = read.xlsx("hsbdemo.xlsx", colNames = FALSE)
head(dd)
colnames(dd)[1] = "id"
colnames(dd)[2] = "female"
colnames(dd)[3] = "ses"
colnames(dd)[4] = "schtyp"
colnames(dd)[5] = "prog"
colnames(dd)[6] = "read"
colnames(dd)[7] = "write"
colnames(dd)[8] = "math"
colnames(dd)[9] = "science"
colnames(dd)[10] = "socst"
colnames(dd)[11] = "honors"
colnames(dd)[12] = "awards"
colnames(dd)[13] = "cid"
head(dd)
#This dataset is for 200 students.
# read is a continuous variable denoting "Reading test score"
# math is a continuous variable denoting "Math test score"
# write is a continuous variable denoting "Writing score"
# socst is a continuous variable denoting "Social Studies score"
#Let us first do an easy regression for read (response) on math and socst
reg1 = lm(read ~ math + socst, data = dd)
summary(reg1)
#Both of the regression coefficients are positive which makes sense.
#Now let us throw in an interaction term which can be done in two ways:
reg2 = lm(read ~ math + socst + math:socst, data = dd)
summary(reg2)
#or
reg3 = lm(read ~ math*socst, data = dd)
summary(reg3)
#The interaction term has positive regression coefficient but the main effects have negative coefficients. Is the fitted function EM? Let us check this. It is easy to see that the function b0+b1*x1 + b2*x2 + b3*x1*x2 is EM if and only if b3 geq 0, b1 + b3 x2 ge 0 for all x2 and b2 + b3 x1 ge 0 for all x1. These constraints are easily checkable here
min(reg2$coefficients[2] + (reg2$coefficients[4])*dd$socst)
min(reg2$coefficients[3] + (reg2$coefficients[4])*dd$math)
#Indeed this seems to be true so we are fitting an EM function here by linear regression here. What do we get if we now fit our method?
dd %>% select("math","socst")
dd %>% select(c("math","socst"))
dd %>% select(one_of(c("math","socst")))
type(dd)
dd$math
dd
#A standard dataset for illustrating continuous by continuous interactions in linear regression is the hsbdemo data (see e.g., https://stats.idre.ucla.edu/r/faq/how-can-i-explain-a-continuous-by-continuous-interaction/ or http://web.pdx.edu/~joel8/resources/ConceptualPresentationResources/ContinuousByContinousInteractions_walkthrough_v2.pdf) I was wondering what our EM gives and how it compares with the results of linear regressions for this dataset. Let me first fit the usual linear models.
#Open the hsbdemo dataset
#It is in an .xlsx file
library(openxlsx)
dd = read.xlsx("hsbdemo.xlsx", colNames = FALSE)
head(dd)
colnames(dd)[1] = "id"
colnames(dd)[2] = "female"
colnames(dd)[3] = "ses"
colnames(dd)[4] = "schtyp"
colnames(dd)[5] = "prog"
colnames(dd)[6] = "read"
colnames(dd)[7] = "write"
colnames(dd)[8] = "math"
colnames(dd)[9] = "science"
colnames(dd)[10] = "socst"
colnames(dd)[11] = "honors"
colnames(dd)[12] = "awards"
colnames(dd)[13] = "cid"
head(dd)
#This dataset is for 200 students.
# read is a continuous variable denoting "Reading test score"
# math is a continuous variable denoting "Math test score"
# write is a continuous variable denoting "Writing score"
# socst is a continuous variable denoting "Social Studies score"
#Let us first do an easy regression for read (response) on math and socst
reg1 = lm(read ~ math + socst, data = dd)
summary(reg1)
#Both of the regression coefficients are positive which makes sense.
#Now let us throw in an interaction term which can be done in two ways:
reg2 = lm(read ~ math + socst + math:socst, data = dd)
summary(reg2)
#or
reg3 = lm(read ~ math*socst, data = dd)
summary(reg3)
#The interaction term has positive regression coefficient but the main effects have negative coefficients. Is the fitted function EM? Let us check this. It is easy to see that the function b0+b1*x1 + b2*x2 + b3*x1*x2 is EM if and only if b3 geq 0, b1 + b3 x2 ge 0 for all x2 and b2 + b3 x1 ge 0 for all x1. These constraints are easily checkable here
min(reg2$coefficients[2] + (reg2$coefficients[4])*dd$socst)
min(reg2$coefficients[3] + (reg2$coefficients[4])*dd$math)
#Indeed this seems to be true so we are fitting an EM function here by linear regression here. What do we get if we now fit our method?
load("~/Dropbox/EntirelyMontone/hsbdemo/.RData")
#A standard dataset for illustrating continuous by continuous interactions in linear regression is the hsbdemo data (see e.g., https://stats.idre.ucla.edu/r/faq/how-can-i-explain-a-continuous-by-continuous-interaction/ or http://web.pdx.edu/~joel8/resources/ConceptualPresentationResources/ContinuousByContinousInteractions_walkthrough_v2.pdf) I was wondering what our EM gives and how it compares with the results of linear regressions for this dataset. Let me first fit the usual linear models.
#Open the hsbdemo dataset
#It is in an .xlsx file
library(openxlsx)
dd = read.xlsx("hsbdemo.xlsx", colNames = FALSE)
head(dd)
colnames(dd)[1] = "id"
colnames(dd)[2] = "female"
colnames(dd)[3] = "ses"
colnames(dd)[4] = "schtyp"
colnames(dd)[5] = "prog"
colnames(dd)[6] = "read"
colnames(dd)[7] = "write"
colnames(dd)[8] = "math"
colnames(dd)[9] = "science"
colnames(dd)[10] = "socst"
colnames(dd)[11] = "honors"
colnames(dd)[12] = "awards"
colnames(dd)[13] = "cid"
head(dd)
#This dataset is for 200 students.
# read is a continuous variable denoting "Reading test score"
# math is a continuous variable denoting "Math test score"
# write is a continuous variable denoting "Writing score"
# socst is a continuous variable denoting "Social Studies score"
#Let us first do an easy regression for read (response) on math and socst
reg1 = lm(read ~ math + socst, data = dd)
summary(reg1)
#Both of the regression coefficients are positive which makes sense.
#Now let us throw in an interaction term which can be done in two ways:
reg2 = lm(read ~ math + socst + math:socst, data = dd)
summary(reg2)
#or
reg3 = lm(read ~ math*socst, data = dd)
summary(reg3)
#The interaction term has positive regression coefficient but the main effects have negative coefficients. Is the fitted function EM? Let us check this. It is easy to see that the function b0+b1*x1 + b2*x2 + b3*x1*x2 is EM if and only if b3 geq 0, b1 + b3 x2 ge 0 for all x2 and b2 + b3 x1 ge 0 for all x1. These constraints are easily checkable here
min(reg2$coefficients[2] + (reg2$coefficients[4])*dd$socst)
min(reg2$coefficients[3] + (reg2$coefficients[4])*dd$math)
#Indeed this seems to be true so we are fitting an EM function here by linear regression here. What do we get if we now fit our method?
dd$math
dd$socst
library(ggplot2)
ggplot(mtcars, aes(x = dd$math, y = dd$socst)) +
geom_point()
install.packages("ggplot2")
library(ggplot2)
ggplot(mtcars, aes(x = dd$math, y = dd$socst)) +
geom_point()
install.packages("pillar")
install.packages("ggplot2", dependencies = TRUE)
library("ggplot2")
library(ggplot2)
# ipak function: install and load multiple R packages.
# check to see if packages are installed. Install them if they are not, then load them into the R session.
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("ggplot2", "plyr", "reshape2", "RColorBrewer", "scales", "grid")
ipak(packages)
install.packages("ggplot2")
require("Rmosek")
cd Downloads
ls
getwd()
source("/mosek/9.1/tools/platform/osx64x86/rmosek/builder.R")
source("mosek/9.1/tools/platform/osx64x86/rmosek/builder.R")
attachbuilder()
install.rmosek()
attachbuilder()
install.rmosek()
install.packages("Rmosek", type="source", INSTALL_opts="--no-multiarch", repos="http://download.mosek.com/R/8")
show(install.rmosek())
getwd()
source("mosek/9.1/tools/platform/osx64x86/rmosek/builder.R")
attachbuilder(what_mosek_bindir="/Users/hanshengjiang/mosek/9.1/tools/platform/osx64x86/bin", pos=2L, name="Rmosek:builder", warn.conflicts=TRUE)
show(install.rmosek())
source("mosek/9.1/tools/platform/osx64x86/rmosek/builder.R")
attachbuilder(what_mosek_bindir="/Users/hanshengjiang/mosek/9.1/tools/platform/osx64x86/bin", pos=2L, name="Rmosek:builder", warn.conflicts=TRUE)
attachbuilder()
install.rmosek()
source("./../simulations12/lib.R")
source("./../simulations12/functions.R")
source("./../simulations12/plotting.R")
require(lattice)
d <- 2
# n <- 20
# design <- matrix(runif(n * d), n)
# design <- matrix(c(0, 0,  1, 1, 0, 1, 0, 1), 4)
N <- 20
#design <- expand.grid(list((0:N)/N, (0:N)/N))
# design <- matrix(rep((0:N)/N, 2), ncol=2)
dd <- read.csv("./../simulations12/hsbdemo/hsbdemo.csv")
#remove first column
dd <- dd[,-1]
dd <- dd[,c("math", "socst", "read")]
temp <- matrix(, nrow = 3, ncol = 3)
temp[1,] <- numeric(1/2, 1/3, 1/6)
temp[1,] <- (1/2, 1/3, 1/6)
temp[1,] <- tuple(1/2, 1/3, 1/6)
temp[1,1] <- 1/2
temp[1,2] <- 1/3
temp[1,3] <- 1/6
temp[2,1] <- 0
temp[2,2] <- 1/3
temp[2,3] <- 2/3
temp[3,1] <- 1/2
temp[3,2] <- 0
temp[3,3] <- 1/2
temp
temp %*% temp
temp
temp2 <- temp %* temp2
temp2 <- temp %*% temp
temp2 %*% temp
library(MASS)
temp3<- temp2 %*% temp
as.fractions(temp3)
pi <- matrix(, nrow = 1, ncol =3)
pi[1,1] <- 1/4
pi[1,2] <- 1/4
pi[1,3] <- 1/2
pi
pi %*% temp3
as.fractions(pi %*% temp3)
43/216 + 169/432*2
curve(dnorm(x, mean=219, sd=41), from = 0, to = 400)
curve(dnorm(x, mean=244, sd=51), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = 0, to = 400)
curve(dnorm(x, mean=5, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7)
curve(dnorm(x, mean=3, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7)
curve(dnorm(x, mean=3, sd=1) +dnorm(x, mean=1, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7)
curve(dnorm(x, mean=3, sd=1) +dnorm(x, mean=1, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7)
curve(dnorm(x, mean=3, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7)
curve(dnorm(x, mean=3, sd=1), add = TRUE, col = 2)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=3, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = red)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 1)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 3)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 4)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 5)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 7)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 6)
curve(dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3,col = 8)
curve(dnorm(x, mean=3, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=3, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 1, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 3, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=3, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 1, lwd = 3)
curve(dnorm(x, mean=3, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 1, lwd = 3)
curve(dnorm(x, mean=3, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=3, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 7, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=4, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=4, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 8, lwd = 3)
curve(dnorm(x, mean=4, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=3.5, sd=1) + dnorm(x, mean=1, sd=1), from = -3, to = 8, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=3.5, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=4, sd=1) + dnorm(x, mean=2.5, sd=1)+ dnorm(x, mean=1, sd=1), from = -3, to = 8, lwd = 3)
curve(dnorm(x, mean=6, sd=1) + dnorm(x, mean=3.5, sd=1)+ dnorm(x, mean=1, sd=1), from = -3, to = 12, lwd = 3)
curve(dnorm(x, mean=3.5, sd=1), add = TRUE, col = 4, lwd = 3)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3)
curve(dnorm(x, mean=6, sd=1), add = TRUE, col = 3, lwd = 3)
curve(dnorm(x, mean=6, sd=1) + dnorm(x, mean=3.5, sd=1)+ dnorm(x, mean=1, sd=1), from = -3, to = 12, lwd = 3)
curve(dnorm(x, mean=6, sd=1), add = TRUE, col = 3, lwd = 3,lty=2)
curve(dnorm(x, mean=6, sd=1), add = TRUE, col = 3, lwd = 3,lty=2)
curve(dnorm(x, mean=6, sd=1) + dnorm(x, mean=3.5, sd=1)+ dnorm(x, mean=1, sd=1), from = -3, to = 12, lwd = 3)
curve(dnorm(x, mean=6, sd=1), add = TRUE, col = 3, lwd = 3,lty=2)
curve(dnorm(x, mean=1, sd=1), add = TRUE, col = 2, lwd = 3,lty=2)
curve(dnorm(x, mean=3.5, sd=1), add = TRUE, col = 4, lwd = 3,lty=2)
install.packages("car")
R.version
install.packages("devtools",dependencies = TRUE)
install.packages("devtools",dependencies = TRUE)
devtools::install_github("shuyang1987/multilevelMatching")
library("Matching")
library(multilevelMatching)
simulated_data <- multilevelMatching::simulated_data
knitr::kable(head(simulated_data), digits = 2)
outcome <- simulated_data$outcome
treatment <- simulated_data$treatment
covar_matrix <- as.matrix(
simulated_data[ ,names(simulated_data) %in% paste0("covar", 1:6)]
)
identifying_names <- paste0(
rep(letters[1:25],each = 12), rep(letters[1:25], 12)
)
names(treatment) <- identifying_names
set.seed(123)
fit <- multiMatch(
Y = outcome,
W = treatment,
X = covar_matrix,
match_on = "covariates"
)
fit
match_on <- "multinom"
# match_on <- "polr"
set.seed(123)
fit2 <- multiMatch(
Y = outcome,
W = treatment,
X = covar_matrix,
match_on = match_on,
trimming = FALSE
)
fit
library(multilevelMatching)
simulated_data <- multilevelMatching::simulated_data
knitr::kable(head(simulated_data), digits = 2)
outcome <- simulated_data$outcome
treatment <- simulated_data$treatment
covar_matrix <- as.matrix(
simulated_data[ ,names(simulated_data) %in% paste0("covar", 1:6)]
)
identifying_names <- paste0(
rep(letters[1:25],each = 12), rep(letters[1:25], 12)
)
names(treatment) <- identifying_names
simulated_data
library("kayadata")
dataset("td_values")
datas("td_values")
data("td_values")
force(td_values)
td <- data("td_values")
force(td_values)
View(td_values)
setwd("~/Documents/python_scripts/npmle_git/data")
write.csv(td,"./td_values.csv")
write.csv(td_values,"./td_values.csv")
